# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n8cCIEGOGO99GZSTHYM-BoZ9T6UuOYHr
"""

import zipfile

# Replace "zip_file_name.zip" with the name of your uploaded zip archive
with zipfile.ZipFile("/content/dataset_tweets.zip", "r") as zip_ref:
    zip_ref.extractall("destination_directory/")

import os
import json
import csv

# Define input and output directories
input_dir = "/content/destination_directory/dataset_tweets_rm/positive/tweetP"
output_dir = "/content/output"
train_data=[]
train_data_label= []
# Loop through all JSON files in input directory
for filename in os.listdir(input_dir):
    if filename.endswith('.json'):
        # Open JSON file and parse contents
        with open(os.path.join(input_dir, filename), 'r') as json_file:
            data = json.load(json_file)
        
        # Extract information from dictionary
        tweet_text = data['text']
        train_data.append(tweet_text)
        train_data_label.append(1)
        user_name = data['user']['name']
        quoted_tweet = data.get('quoted_status', {}).get('text', '')

        # Write information to CSV file
        with open(os.path.join(output_dir, filename[:-5] + '.csv'), 'w', newline='') as csv_file:
            writer = csv.writer(csv_file)
            writer.writerow(['Tweet Text', 'label'])
            writer.writerow([tweet_text, "1"])

import os
import json
import csv

# Define input and output directories
input_dir = "/content/destination_directory/dataset_tweets_rm/negative/tweetN"
output_dir = "/content/output"


# Loop through all JSON files in input directory
for filename in os.listdir(input_dir):
    if filename.endswith('.json'):
        # Open JSON file and parse contents
        with open(os.path.join(input_dir, filename), 'r') as json_file:
            data = json.load(json_file)
        
        # Extract information from dictionary
        tweet_text = data['text']
        train_data.append(tweet_text)
        train_data_label.append(0)
        user_name = data['user']['name']
        quoted_tweet = data.get('quoted_status', {}).get('text', '')

        # Write information to CSV file
        with open(os.path.join(output_dir, filename[:-5] + '.csv'), 'w', newline='') as csv_file:
            writer = csv.writer(csv_file)
            writer.writerow(['Tweet Text', 'label'])
            writer.writerow([tweet_text, "0"])

import os
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(train_data,train_data_label,test_size=0.2, random_state=42)

# Initialize the TF-IDF vectorizer
tfidf = TfidfVectorizer()

# Transform the training data using the TF-IDF vectorizer
X_train_tfidf = tfidf.fit_transform(X_train)

# Initialize the logistic regression model
lr = LogisticRegression()

# Train the logistic regression model on the transformed training data and training labels
lr.fit(X_train_tfidf, y_train)

# Transform the testing data using the TF-IDF vectorizer
X_test_tfidf = tfidf.transform(X_test)

# Predict the testing labels using the trained logistic regression model
y_pred = lr.predict(X_test_tfidf)

# Print the accuracy of the logistic regression model on the testing data
print('Accuracy:', lr.score(X_test_tfidf, y_test))